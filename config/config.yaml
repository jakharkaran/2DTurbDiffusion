logging_params: # Logging for Weights and biases
  log_to_screen: !!bool True # Control detailed print statements for debugging/monitoring
  diagnostic_logs: !!bool False # Log Diagnistic  to screen
  log_to_wandb: !!bool True # True False
  wandb_table_logging_interval: 10 # not setup
  wandb_project: 'test'
  wandb_group: 'static'
  wandb_name: 'test'

dataset_params:
  # the data is contained in the 'data' folder in the root directory. there should be another 'mean_std.npz' file in the same folder with mean ans std values
  # data_dir: 'data_mnist/train/images'
  data_dir: '../data/Re500_fkx4fky4_r0.1_b20/NoSGS/NX64/dt0.0005_IC1/'
  
  file_range: [5000, 7500] # range of files to load
  # total samples used for training = file_range[1] - file_range[0] // step_size
  step_size: 1 # step size for data loading (every nth sample)
  condition_step_size: 1 # step size for conditioning data loading (every nth sample)
  num_prev_conditioning_steps : 1 # 1 2 3 4 # Number of previous time steps to use for conditioning t-1, t-2, t-3, t-4
  downsample_factor: 1
  downsample_procedure: 'spectral' # spectral physical
  normalize: !!bool True

diffusion_params:
  conditional: !!bool False # True False
  condition_noise: !!bool False  # True False Noise is added to the conditioning while training and sampling ** Not implemented
  num_timesteps : 1000
  beta_start : 0.0001
  beta_end : 0.02

model_params: # U-NET
  padding_mode: 'circular' # Padding of conv2d layers. 'zeros': standard non-periodic UNET; 'circular': periodic UNET (maybe need coord_conv=True for UDM )
  im_channels : 2 # 2 when conditional=False
  pred_channels: 2 # =im_channels for conditional=False; 
  cond_channels: 2 # =2*(num_prev_conditioning_steps); 2,4,6... when conditional=True;Will be added to input channels if conditional=True; = 0 for conditional=False
  coord_conv: !!bool True # True False # Concatenate coordinates with input channels; True: Add +2 channels to input_channels
  # input_channels = im_channels + cond_channels (if conditional) + 2 (if coord_conv)
  # Note: A periodic UNET is translational invariant leading to translational invariant outputs; We need to feed positional argumenets to produce postional aware outputs (coord_conv=True)
  im_size : 64
  down_channels : [32, 64, 128, 256]
  mid_channels : [256, 256, 128]
  down_sample : [True, True, False]
  time_emb_dim : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  num_heads : 4

train_params:
  task_name: 'test'
  effective_batch_size: 16 # batch_size per gpu = effective_batch_size / num_gpus
  num_epochs: 400
  optimizer: 'adamw' # 'adam' 'adamw'
  scheduler: null # 'CosineAnnealingLR' 'ReduceLROnPlateau'
  lr: 1e-4
  lr_min: 1e-6 # Minimum learning rate for CosineAnnealingLR
  warmup: !!bool False # Warmup for LR scheduler (Start with low LR and then increase)
  warmup_start_factor: 0.001 
  warmup_total_iters: 5 # Warm-up learning rate for the first N epochs
  weight_decay: 1e-6 # L2 regularization Loss
  clip_grad_norm: null # 1.0 # Gradient clipping to avoid exploding gradients, null for no clipping
  loss: 'noise' # sample noise 
  global_seed: 1 # Global seed for training reproducibility

  divergence_loss: !!bool False # True False
  divergence_loss_type: 'denoise_sample' # denoise_sample (need loss = noise), direct_sample (loss == noise or sample)
  divergence_loss_weight: 1

  # Following only used for divergence_loss_type: denoise_sample
  denoise_sample_timestep: 1 # 1 - num_timesteps  
  denoise_sample_batch_ratio: 0.15 # % of batch used for divergence loss, rest of the samples used for mse loss

  model_collapse: !!bool False # True False # Not implemented for conditional
  model_collapse_type: 'all_gen' # all_gen last_gen # All generations vs last generation
  model_collapse_gen: 1 # 1 2 3 4 5 # Can't be gen 0 - model_collapse should be False for gen 0

  ckpt_name: 'ddpm_ckpt.pth'
  best_ckpt_name: 'best_ddpm_ckpt.pth'

# For Sampling (Inference)
sample_params:
  global_seed: null # Global seed for reproducibility; If null, it will be random seed - It should be null to produce different samples for each ensemble

  sampler: 'dpm-solver++' # ddpm ddim dpm-solver dpm-solver++ # Sampling method
  dpm_steps: 50       # ↓ = faster, ↑ = better quality
  dpm_order: 3       # '1' '2' '3'  (3 recommended for unconditional; 1: equivalent to DDIM)
  dpm_method: "singlestep"  # 'singlestep' 'multistep' 'adaptive'
  dpm_skip: "time_uniform"  # 'time_uniform' 'logSNR'
  dpm_guidance: 'uncond'    # 'uncond' # only one comaptible with current code

  sample_batch_size : 32 # Inference data batch size
  num_sample_batch : 100 # number of samples = sample_batch_size * num_sample_batch
  sample_file_start_idx : 5000  # For conditional:True, first real frame used to seed sampling
  save_image: !!bool True # Saves snapshots of emulated data
  save_data: !!bool True # Saved emulated data # First five batches will always be saved
